_base_ = '../../_base_/default_runtime.py'

load_from = '/home/cvlab123/mmaction2/checkpoints/stgcnpp_8xb16-joint-u100-80e_ntu60-xsub-keypoint-2d_20221228-86e1e77a.pth'
# load_from = '/home/cvlab123/mmaction2/work_dirs/916_rtmpose_all_2D_joint_motion/best_acc_top1_epoch_10.pth'
imports = ('mmaction.datasets.transforms.pose_transforms','fias_custom_loss.custom_loss')

class_weight = [0.97, 0.78, 1.06, 0.96, 1.08, 1.02, 1.1, 1.04, 1.03, 1.03]

randomness = dict(seed=42, deterministic=True)
launcher_cfg = dict(env_vars=dict(CUBLAS_WORKSPACE_CONFIG=':4096:8'))
model = dict(
    type='RecognizerGCN',
    data_preprocessor=dict(
        type='mmaction.ActionDataPreprocessor'),
    backbone=dict(
        type='STGCN',
        gcn_adaptive='init',
        gcn_with_res=True,
        tcn_type='mstcn',
        graph_cfg=dict(layout='coco', mode='spatial')),
    # 改這個 cls_head 來更改 class number (現在 3 * 3 = 9)
    cls_head=dict(
        type='GCNHead', 
        # ✅ CRITICAL: Update num_classes to 10 to include 'idle'
        num_classes=10, 
        in_channels=256,
        # # # ✅ NEW: Define the loss function to include class weights
        loss_cls=dict(
            type='HierarchicalExerciseLoss',
            coarse_penalty_weight=2
        )
    )
)

dataset_type = 'PoseDataset'

ann_file_test = '/home/cvlab123/data/pickle/friend_test.pkl'
# 要改成我們的 .pkl
# both
# ann_file_test = '/home/cvlab123/data/pickle/rtmpose_2D_all.pkl'
# back
# ann_file_test = '/home/cvlab123/data/pickle/rtmpose_2D_back.pkl'
# front
# ann_file_test = '/home/cvlab123/data/pickle/rtmpose_2D_front.pkl'

# ann_file_train = '/home/cvlab123/data/pickle/rtmpose_2D_back.pkl'
ann_file_train = '/home/cvlab123/data/pickle/1101_Ourdataset_with_idle.pkl'
# ann_file_train = '/home/cvlab123/data/pickle/rtmpose_2D_front.pkl'

train_pipeline = [
    dict(type='PreNormalize2D'),
    dict(type='GenSkeFeat', dataset='coco', feats=['j']),
    dict(type='UniformSampleFrames', clip_len=40),
    dict(type='PoseDecode'),
    # --- ✅ AUGMENTATIONS ADDED HERE ---
    dict(type='RandomRot', theta=0.3),  # Randomly rotate the skeleton
    dict(type='RandomScale', scale=0.1), # Randomly zoom in/out
    dict(type='FormatGCNInput', num_person=1),
    dict(type='PackActionInputs')
]
val_pipeline = [
    dict(type='PreNormalize2D'),
    dict(type='GenSkeFeat', dataset='coco', feats=['j']),
    dict(
        type='UniformSampleFrames', clip_len=40, num_clips=1, test_mode=True),
    dict(type='PoseDecode'),
    dict(type='FormatGCNInput', num_person=1),
    dict(type='PackActionInputs')
]
test_pipeline = [
    dict(type='PreNormalize2D'),
    dict(type='GenSkeFeat', dataset='coco', feats=['j']),
    dict(
        type='UniformSampleFrames', clip_len=40, num_clips=1,
        test_mode=True),
    dict(type='PoseDecode'),
    dict(type='FormatGCNInput', num_person=1),
    dict(type='PackActionInputs')
]

train_dataloader = dict(
    batch_size=16,
    num_workers=2,
    persistent_workers=True,
    sampler=dict(type='DefaultSampler', shuffle=True),
    dataset=dict(
        type='RepeatDataset',
        times=5,
        dataset=dict(
            type=dataset_type,
            ann_file=ann_file_train,
            pipeline=train_pipeline,
            split='xsub_train')))
val_dataloader = dict(
    batch_size=16,
    num_workers=2,
    persistent_workers=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_train,
        pipeline=val_pipeline,
        split='xsub_val',
        test_mode=True))
test_dataloader = dict(
    batch_size=1,
    num_workers=0,
    persistent_workers=False,
    sampler=dict(type='DefaultSampler', shuffle=False),
    dataset=dict(
        type=dataset_type,
        ann_file=ann_file_test,
        pipeline=test_pipeline,
        split='xsub_test',
        test_mode=True))

val_evaluator = [dict(type='AccMetric')]
test_evaluator = [
        dict(type='AccMetric') 
]

train_cfg = dict(
    type='EpochBasedTrainLoop', max_epochs=20, val_begin=1, val_interval=1)
val_cfg = dict(type='ValLoop')
test_cfg = dict(type='TestLoop')

param_scheduler = [
    dict(
        type='CosineAnnealingLR',
        eta_min=0,
        T_max=20,
        by_epoch=True,
        convert_to_iter_based=True)
]

optim_wrapper = dict(
    optimizer=dict(
        type='SGD', lr=0.001, momentum=0.9, weight_decay=0.0005, nesterov=True))

default_hooks = dict(
    checkpoint=dict(
        type='CheckpointHook',
        interval=1,               # Check after every epoch
        save_best='acc/top1',     # Save the model with the best validation accuracy
        rule='greater',           # Higher accuracy is better
        max_keep_ckpts=1          # Only keep the single best one
    ),
    logger=dict(interval=100)
)

auto_scale_lr = dict(enable=False, base_batch_size=128)
